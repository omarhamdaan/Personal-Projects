{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d356590",
   "metadata": {
    "id": "6d356590"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895d5112",
   "metadata": {
    "id": "895d5112"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv (\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6107940a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6107940a",
    "outputId": "9db3ccb0-7f0d-4dc6-8e7d-32da861e9929"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78094, 126)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e9bc64",
   "metadata": {
    "id": "53e9bc64"
   },
   "outputs": [],
   "source": [
    "Y = df['diabetes_mellitus'] ## Label, target variable, 0 --> doesn't have diabetes_mellitus, \n",
    "                                                        #   1 --> does have diabetes_mellitus\n",
    "X = df.drop(columns=['diabetes_mellitus']) ## 125 feature data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af548f83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af548f83",
    "outputId": "29ff8020-2a1d-4e1b-ab46-993d04b20195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78094, 125)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa6ad5fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa6ad5fe",
    "outputId": "73402cda-4dc5-4b16-9e98-0d6847f908af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78094,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3832e9e-c178-4456-86a8-820d97de51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data: clean, impute, scale, and encode\n",
    "def preprocess_data(train_data, test_data):\n",
    "    # Columns that are not needed or irrelevant to the model\n",
    "    remove_columns = [\"hospital_id\", \"nan_counts\", \"icu_id\"]\n",
    "    train_data.drop(remove_columns, axis=1, inplace=True)\n",
    "    test_data.drop(remove_columns, axis=1, inplace=True)\n",
    "\n",
    "    # Separate target variable\n",
    "    y_train = train_data['diabetes_mellitus']\n",
    "    x_train = train_data.drop(columns=['diabetes_mellitus'])\n",
    "\n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = x_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_cols = x_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Impute missing values in numeric columns\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    x_train[numeric_cols] = imputer.fit_transform(x_train[numeric_cols])\n",
    "    test_data[numeric_cols] = imputer.transform(test_data[numeric_cols])\n",
    "\n",
    "    # Scale numeric columns\n",
    "    scaler = StandardScaler()\n",
    "    x_train[numeric_cols] = scaler.fit_transform(x_train[numeric_cols])\n",
    "    test_data[numeric_cols] = scaler.transform(test_data[numeric_cols])\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    x_train_encoded = pd.get_dummies(x_train, columns=categorical_cols, drop_first=True)\n",
    "    test_data_encoded = pd.get_dummies(test_data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Align train and test data, ensuring they have the same columns\n",
    "    x_train_encoded, test_data_encoded = x_train_encoded.align(test_data_encoded, join='inner', axis=1, fill_value=0)\n",
    "\n",
    "    return x_train_encoded, y_train, test_data_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74a6cba-c0da-46fc-bf3e-ce51e4e9aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        # Using regularization to prevent overfitting\n",
    "        keras.layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), input_shape=(input_shape,)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train an ensemble of models for robust predictions\n",
    "def ensemble_model(x_train, y_train, x_val, y_val, num_models=1):\n",
    "    models = []\n",
    "    for _ in range(num_models):\n",
    "        model = build_model(x_train.shape[1])\n",
    "        # Convert data to a consistent type\n",
    "        x_train_tensor = tf.convert_to_tensor(x_train.astype('float32'))\n",
    "        y_train_tensor = tf.convert_to_tensor(y_train.astype('float32'))\n",
    "        x_val_tensor = tf.convert_to_tensor(x_val.astype('float32'))\n",
    "        y_val_tensor = tf.convert_to_tensor(y_val.astype('float32'))\n",
    "\n",
    "        model.fit(x_train_tensor, y_train_tensor, epochs=10, batch_size=64, validation_data=(x_val_tensor, y_val_tensor))\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5670b4b6-f117-40bc-bd06-73a821a1ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data using the ensemble\n",
    "def predict_test_data(models, test_data_encoded, threshold=0.5):\n",
    "    # Convert to TensorFlow tensor and ensure type consistency\n",
    "    test_data_tensor = tf.convert_to_tensor(test_data_encoded.astype('float32'))\n",
    "\n",
    "    # Averaging predictions from all models\n",
    "    test_predictions = np.mean([model.predict(test_data_tensor) for model in models], axis=0)\n",
    "    # Convert to binary outcome\n",
    "    test_predictions_binary = np.where(test_predictions >= threshold, 1, 0)\n",
    "    return test_predictions_binary.flatten()\n",
    "\n",
    "# Create a submission file for the predictions\n",
    "def save_submission(predictions_binary, test_data, filename='Diabetes_Mellitus_Prediction_DeepLearning Approach Output.csv'):\n",
    "    submission_df = pd.DataFrame()\n",
    "    submission_df['ID'] = test_encounter_id['encounter_id']\n",
    "    submission_df['diabetes_mellitus'] = predictions_binary\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdae324-2f23-4528-b7aa-770e67312fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "855/855 [==============================] - 4s 4ms/step - loss: 7.5601 - accuracy: 0.7955 - val_loss: 3.4281 - val_accuracy: 0.8063\n",
      "Epoch 2/10\n",
      "855/855 [==============================] - 3s 4ms/step - loss: 1.7245 - accuracy: 0.8090 - val_loss: 0.8319 - val_accuracy: 0.8022\n",
      "Epoch 3/10\n",
      "855/855 [==============================] - 3s 4ms/step - loss: 0.6404 - accuracy: 0.8012 - val_loss: 0.5407 - val_accuracy: 0.8006\n",
      "Epoch 4/10\n",
      "855/855 [==============================] - 3s 4ms/step - loss: 0.5159 - accuracy: 0.8007 - val_loss: 0.4932 - val_accuracy: 0.8042\n",
      "Epoch 5/10\n",
      "855/855 [==============================] - 3s 3ms/step - loss: 0.4899 - accuracy: 0.8032 - val_loss: 0.4772 - val_accuracy: 0.8082\n",
      "Epoch 6/10\n",
      "855/855 [==============================] - 3s 4ms/step - loss: 0.4791 - accuracy: 0.8045 - val_loss: 0.4701 - val_accuracy: 0.8088\n",
      "Epoch 7/10\n",
      "855/855 [==============================] - 3s 4ms/step - loss: 0.4733 - accuracy: 0.8057 - val_loss: 0.4639 - val_accuracy: 0.8133\n",
      "Epoch 8/10\n",
      "855/855 [==============================] - 4s 5ms/step - loss: 0.4701 - accuracy: 0.8065 - val_loss: 0.4611 - val_accuracy: 0.8134\n",
      "Epoch 9/10\n",
      "855/855 [==============================] - 4s 5ms/step - loss: 0.4681 - accuracy: 0.8087 - val_loss: 0.4595 - val_accuracy: 0.8119\n",
      "Epoch 10/10\n",
      "855/855 [==============================] - 4s 5ms/step - loss: 0.4649 - accuracy: 0.8098 - val_loss: 0.4573 - val_accuracy: 0.8145\n",
      "1627/1627 [==============================] - 2s 1ms/step\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "train_data = pd.read_csv(\"diabetes.csv\")\n",
    "test_data = pd.read_csv(\"diabetes_test_unlabeled.csv\")\n",
    "test_encounter_id=pd.read_csv(\"diabetes_test_unlabeled.csv\")\n",
    "\n",
    "x_train_encoded, y_train, test_data_encoded = preprocess_data(train_data, test_data)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_encoded, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train models and predict\n",
    "models = ensemble_model(x_train, y_train, x_val, y_val, num_models=1)\n",
    "test_predictions_binary = predict_test_data(models, test_data_encoded)\n",
    "\n",
    "# Save predictions to a file\n",
    "save_submission(test_predictions_binary, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c9f42-39b4-4d58-9cce-cfa370f43283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
